# GaussGym + Google Veo: Photorealistic Scene Generation Research

**Status**: Evaluation Complete - Implementation Recommendations
**Last Updated**: 2025-01-14
**Research Depth**: Comprehensive Technical Analysis

---

## Executive Summary

**Recommendation**: Implement **Phase-Based Approach**
1. **Immediate**: Enhance procedural scenes (current system)
2. **Month 1**: Integrate Luma AI for video-to-3D (RECOMMENDED)
3. **Month 3**: Add Blender procedural pipeline
4. **Month 6+**: Evaluate GaussGym+Veo for marketing/hero shots only

**Why NOT Full GaussGym Now?**
- âŒ Overkill for robotics development (users need speed, not photorealism)
- âŒ Expensive ($1-3/scene + 30 min processing kills iteration speed)
- âŒ Complex (2 months dev time vs 2 weeks for Luma AI)
- âœ… Better alternative: Luma AI gives 80% benefits at 20% complexity

---

## What is GaussGym?

### Overview
**GaussGym** is a cutting-edge real-to-sim framework combining:
- **3D Gaussian Splatting** for photorealistic rendering (25x faster than NeRF)
- **IsaacGym-style physics** for rapid simulation (100,000+ steps/second)
- **Neural reconstruction** (NKSR) for collision meshes

**Release Date**: October 2024
**Source**: Research paper + open-source code
**Use Case**: Train visual locomotion policies with photorealistic rendering

### Technical Architecture

```
Input (iPhone video, Veo video, ARKit dataset)
    â†“
VGGT (Structure from Motion)
    â†“
Dense Point Cloud + Normals
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NKSR           â”‚  3D Gaussian    â”‚
â”‚ (Collision)    â”‚  Splatting      â”‚
â”‚                â”‚  (Visual)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Simulation-Ready Scene (physics + rendering)
```

### Key Components

**1. VGGT (Visual Geometry Grounded Transformers)**
- Extracts camera poses from unposed videos
- Generates dense point clouds with normals
- Handles both indoor (ARKitScenes) and outdoor (GrandTour)

**2. NKSR (Neural Kernel Surface Reconstruction)**
- NVIDIA's state-of-the-art mesh reconstruction
- Processes millions of points in seconds
- Generates watertight collision meshes
- Superior to Poisson Surface Reconstruction

**3. 3D Gaussian Splatting (3DGS)**
- Real-time photorealistic rendering
- 25x faster training than NeRF
- Uses gsplat library
- Enables 60+ FPS on consumer GPUs

**4. IsaacGym Integration**
- Vectorized physics simulation
- Supports thousands of parallel environments
- GPU-accelerated

### Accepted Input Formats
- âœ… iPhone/smartphone videos (with intrinsic calibration)
- âœ… ARKit datasets (indoor scans)
- âœ… Large-scale datasets (GrandTour for outdoor)
- âœ… **Generative video (Veo, Sora, etc.)**
- âœ… Any posed image sequence
- âœ… Unposed RGB sequences (via VGGT)

### What It Can't Do
- âŒ Generate scenes from text alone (needs video)
- âŒ Procedural generation
- âŒ Material-specific physics (all surfaces have same friction)
- âŒ Deformables or fluids (rigid-body only)

---

## Google Veo 3.1 Integration

### What is Veo?

**Veo 3.1** is Google DeepMind's state-of-the-art AI video generation model.

**Release**: Early 2025 (3.1 version)
**Access**: Available via Gemini API, Google AI Studio, Vertex AI
**Pricing**: Pay-per-use (not publicly disclosed)

### Capabilities

**Text-to-Video:**
- Generate videos from text prompts
- Multi-view consistency (crucial for 3D reconstruction)
- Physics simulation understanding
- Extended duration support

**Image-to-Video:**
- Up to 3 reference images for consistency
- Product visualization
- Specific style control

**Key Features for 3D:**
- 3D latent diffusion (time as third dimension)
- Environmental understanding
- Spatial coherence across frames
- Realistic camera motion

### Veo â†’ 3D Reconstruction Pipeline

```
Text Prompt: "warehouse with tall shelves and boxes"
    â†“
Veo 3.1 API (generate 30-second walkthrough video)
    â†“
Video File (MP4, multi-view consistent)
    â†“
VGGT (extract camera poses + point cloud)
    â†“
NKSR (collision mesh) + 3DGS Training (visuals)
    â†“
3D Scene ready for simulation
```

### Challenges

1. **Inconsistency**: "Veo's outputs can be inconsistent, sometimes requiring re-prompting"
2. **Limited Control**: Text-only camera control is imprecise
3. **Temporal Issues**: Motion blur needed to mitigate flicker
4. **Cost**: Per-video generation fees

---

## Integration with Celestial Studio

### Current System Analysis

**What We Have:**
- **Frontend**: React + Three.js + Rapier physics
- **Scene Generation**: Procedural Python (`backend/simulation/scene_generator.py`)
- **Physics**: Rapier.js (browser) + PyBullet (Modal)
- **Preview**: Real-time 3D in browser
- **Training**: Isaac Lab on Modal GPU

**Scene Generation Flow:**
```
User: "warehouse with mobile robot"
    â†“
LLM extracts: environment, objects, robot
    â†“
SceneGenerator.py creates config
    â†“
Three.js renders in browser (instant)
```

### Integration Architecture Options

#### Option A: GaussGym as Training Backend (RECOMMENDED)

**Use Case**: Keep current system for preview, use GaussGym for photorealistic training

```
User designs scene in browser (Three.js - instant)
    â†“
Choose training backend:
  â€¢ PyBullet (fast, 10K steps/sec)
  â€¢ GaussGym (photorealistic, 100K steps/sec)
    â†“
If GaussGym selected:
  â€¢ Convert URDF + scene config â†’ GaussGym format
  â€¢ Submit to Modal GPU for training
  â€¢ Download trained policy
```

**Pros:**
- âœ… Minimal changes to existing UI
- âœ… Best of both worlds (speed + photorealism)
- âœ… User chooses when photorealism matters

**Cons:**
- âš ï¸ Scene conversion complexity
- âš ï¸ 2 separate rendering pipelines

**Implementation Time**: 1-2 weeks
**Difficulty**: Medium (6/10)

#### Option B: Veo â†’ Scene Generation

**Use Case**: Generate scenes from text using Veo + GaussGym

```
User: "warehouse with tall shelves"
    â†“
Veo API generates video
    â†“
Modal GPU: VGGT + NKSR + 3DGS
    â†“
Export mesh + textures
    â†“
Convert to Three.js scene
```

**Pros:**
- âœ… Photorealistic scenes
- âœ… No manual asset creation

**Cons:**
- âŒ Slow (15-35 min per scene)
- âŒ Expensive ($1-3 per scene)
- âŒ No real-time iteration
- âŒ Veo inconsistency requires re-prompting

**Implementation Time**: 3-4 weeks
**Difficulty**: Hard (8/10)

#### Option C: Hybrid Approach

**Use Case**: Procedural for editing, GaussGym for final rendering

```
User edits scene with procedural tools (fast)
    â†“
"Render Photorealistic" button
    â†“
Generate Veo video of scene
    â†“
Process to 3D via GaussGym
    â†“
Preview in browser (static or streaming)
```

**Pros:**
- âœ… Fast iteration + photorealistic output
- âœ… Best UX

**Cons:**
- âŒ Most complex implementation
- âŒ Two separate pipelines
- âŒ Veo â†’ procedural scene mapping is hard

**Implementation Time**: 4-6 weeks
**Difficulty**: Very Hard (9/10)

---

## Alternative: Luma AI (STRONGLY RECOMMENDED)

### What is Luma AI?

**Luma AI** is a commercial video-to-3D service with production-ready API.

**Website**: https://lumalabs.ai
**API**: Available with paid subscription
**Quality**: Industry-leading NeRF + mesh reconstruction

### Why Luma > GaussGym for Celestial Studio?

| Feature | Luma AI | GaussGym |
|---------|---------|----------|
| **Cost** | $1/scene | $2-4/scene (Modal GPU) |
| **Time** | 30 min | 15-35 min |
| **API** | Simple REST API | DIY implementation |
| **Quality** | Production-ready | Research-grade (may have bugs) |
| **Maintenance** | Zero (managed service) | High (keep up with updates) |
| **Implementation** | 2 weeks | 2 months |
| **Difficulty** | Easy (3/10) | Hard (8/10) |

### Luma Workflow

```
User uploads iPhone video of their warehouse
    â†“
POST to Luma API
    â†“
30 minutes processing
    â†“
Download textured mesh (glTF)
    â†“
Import to Three.js (instant)
```

**Example Code:**
```python
import requests

# Upload video
response = requests.post("https://api.lumalabs.ai/v1/captures",
    files={"video": open("warehouse.mp4", "rb")},
    headers={"Authorization": f"Bearer {api_key}"}
)
capture_id = response.json()["id"]

# Poll for completion
while True:
    status = requests.get(f"https://api.lumalabs.ai/v1/captures/{capture_id}")
    if status.json()["state"] == "completed":
        break
    time.sleep(10)

# Download mesh
mesh_url = status.json()["assets"]["mesh"]["url"]
mesh_file = requests.get(mesh_url).content
```

### Luma Integration Plan

**Week 1**: API integration + backend endpoint
```python
@app.post("/api/scenes/upload-video")
async def upload_scene_video(file: UploadFile):
    """User uploads video of real space"""
    # Upload to Luma
    capture = luma_client.create_capture(file)

    # Store job ID
    db.save_job(user_id, capture.id, status="processing")

    return {"job_id": capture.id, "eta": "30 minutes"}

@app.get("/api/scenes/{job_id}/status")
async def get_scene_status(job_id: str):
    """Poll processing status"""
    status = luma_client.get_status(job_id)

    if status.completed:
        # Download mesh
        mesh = luma_client.download_mesh(job_id)

        # Convert to scene config
        scene = mesh_to_scene_config(mesh)
        db.save_scene(job_id, scene)

        return {"status": "completed", "scene_id": scene.id}

    return {"status": "processing", "progress": status.progress}
```

**Week 2**: Frontend UI
```typescript
// Video upload component
function SceneUploader() {
  const [video, setVideo] = useState(null)
  const [jobId, setJobId] = useState(null)
  const [progress, setProgress] = useState(0)

  const handleUpload = async () => {
    const formData = new FormData()
    formData.append("video", video)

    const response = await fetch("/api/scenes/upload-video", {
      method: "POST",
      body: formData
    })

    const { job_id } = await response.json()
    setJobId(job_id)

    // Poll for completion
    const interval = setInterval(async () => {
      const status = await fetch(`/api/scenes/${job_id}/status`)
      const data = await status.json()

      if (data.status === "completed") {
        clearInterval(interval)
        loadScene(data.scene_id)
      }
      setProgress(data.progress || 0)
    }, 5000)
  }

  return (
    <div>
      <h3>ðŸ“± Scan Your Real Space</h3>
      <p>Record a 360Â° video of your warehouse/office</p>

      <input type="file" accept="video/*" onChange={(e) => setVideo(e.target.files[0])} />
      <button onClick={handleUpload}>Upload & Process</button>

      {jobId && <ProgressBar progress={progress} />}
    </div>
  )
}
```

---

## Technical Requirements

### For GaussGym Implementation

**GPU Requirements:**
- NVIDIA GPU with 24GB VRAM minimum
- Recommended: A100, RTX 3090, RTX 4090
- Modal cost: $2-4/hour

**Software Stack:**
```
Python 3.10+
CUDA 11.8+
PyTorch 2.1+
gsplat (3D Gaussian Splatting)
nksr (Neural Kernel Surface Reconstruction)
```

**Storage:**
- Input video: ~100MB
- Point cloud: ~500MB
- Collision mesh: ~50MB
- Gaussian splat: ~200MB
- **Total per scene**: ~850MB

**Processing Time:**
- VGGT (SfM): 5-10 min
- NKSR (mesh): 2-5 min
- 3DGS training: 10-20 min
- **Total**: 17-35 minutes

**Cost per Scene:**
- Veo API: $0.10-0.50 (estimate)
- Modal GPU: $1-2
- **Total**: $1.10-2.50

### For Luma AI Implementation

**Requirements:**
- API subscription: $99-299/month (1,000-10,000 scenes)
- No GPU needed (managed service)
- Simple REST API

**Processing Time:**
- Upload: 1 min
- Processing: 30 min (automated)
- Download: 1 min
- **Total**: 32 minutes

**Cost per Scene:**
- $0.10-1.00 depending on tier
- **Significantly cheaper at scale**

---

## Implementation Phases (Recommended Path)

### Phase 1: Enhance Current System (IMMEDIATE - 1 week)

**Goal**: Make procedural scenes 10x better

**Actions:**
1. Add more object types to `scene_generator.py`
   - Forklifts, pallets, industrial robots
   - Office furniture, desks, chairs
   - Outdoor terrain, trees, buildings

2. Layout templates
   - Warehouse aisle patterns
   - Factory floor plans
   - Office cubicles

3. Lighting variations
   - Day/night cycles
   - Spotlight positioning
   - Shadows and ambient occlusion

**Cost**: $0
**Impact**: Immediate user value

### Phase 2: Luma AI Integration (MONTH 1 - 2 weeks)

**Goal**: Let users scan real spaces with iPhone

**Actions:**
1. Luma API integration (backend)
2. Video upload UI (frontend)
3. Progress tracking & notifications
4. Mesh â†’ scene config converter

**Features:**
- "Scan Your Space" button
- Upload iPhone video (30-60 seconds)
- Automatic processing (30 min)
- Import to simulator

**Cost**: $99/month + $1/scene
**Impact**: Massive differentiator (no competitor has this)

### Phase 3: Blender Procedural (MONTH 3 - 4 weeks)

**Goal**: Complex procedural scenes via Blender Python

**Actions:**
1. Blender Python scripts for scene types
2. Asset library (open-source models)
3. Export to glTF pipeline
4. Integration with scene generator

**Benefits:**
- Professional-quality assets
- Complex layouts (multi-floor warehouses)
- Reusable components

**Cost**: $0 (open-source)
**Impact**: High-quality scenes without photorealism cost

### Phase 4: GaussGym Evaluation (MONTH 6+ - research)

**Goal**: Assess if GaussGym adds value for training

**Actions:**
1. Install GaussGym locally (test)
2. Run sample scene conversions
3. Compare training results (PyBullet vs GaussGym)
4. Measure ROI (quality vs cost/time)

**Decision Point:**
- If 3DGS improves vision-based policies: implement Option A
- If no significant benefit: skip GaussGym entirely

**Cost**: $50-100 (testing)
**Impact**: Data-driven decision

---

## ROI Analysis

### Current System (Procedural)
- **Cost**: $0
- **Time**: <1 second
- **Quality**: Basic geometric primitives
- **Use Case**: âœ… Algorithm testing, rapid prototyping

### Luma AI
- **Cost**: $1/scene
- **Time**: 30 minutes
- **Quality**: â­â­â­â­â­ Photorealistic
- **Use Case**: âœ… Real-world spaces, client demos, training

### GaussGym + Veo
- **Cost**: $2-3/scene
- **Time**: 30 minutes
- **Quality**: â­â­â­â­â­ Photorealistic + physics
- **Use Case**: âš ï¸ Research, marketing only

### Blender Procedural
- **Cost**: $0
- **Time**: 5-10 minutes (one-time setup)
- **Quality**: â­â­â­â­ Professional assets
- **Use Case**: âœ… Complex layouts, custom scenarios

### Recommendation Matrix

| Use Case | Solution | Why |
|----------|----------|-----|
| Quick testing | Current (Procedural) | Instant, free |
| Real warehouse scan | Luma AI | Easiest, proven |
| Custom complex scene | Blender | Control, quality |
| Marketing video | Veo (no 3D) | $0.50, beautiful |
| Vision policy training | GaussGym (future) | If proven necessary |

---

## Competitive Analysis

### What Competitors Use

**NVIDIA Isaac Sim**:
- USD format
- SimReady assets (1,000+ models)
- Procedural generation
- âŒ No video-to-3D

**Unity Robotics**:
- Prefabs and assets
- Manual scene building
- âŒ No AI generation

**Gazebo**:
- SDF/URDF formats
- Manual modeling
- âŒ No photorealism

### Our Advantage with Luma AI

âœ… **Only platform with iPhone â†’ 3D scene**
âœ… Real-world capture (competitors: manual only)
âœ… 30-minute turnaround (competitors: hours/days)
âœ… No 3D modeling skills needed

**Marketing Angle**: "Scan your warehouse with your phone, train robots in 30 minutes"

---

## Risks & Mitigation

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Luma API changes | Low | High | Version pinning, fallback to Polycam |
| 3DGS browser support | Medium | Medium | Export to mesh fallback |
| Veo inconsistency | High | Medium | Don't rely on Veo for production |
| GaussGym bugs (research code) | High | High | Wait for v1.0 or commercial version |

### Business Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Users don't upload videos | Medium | Medium | Provide sample scenes, tutorials |
| Processing cost too high | Low | High | Tiered pricing, free tier limits |
| Luma shuts down | Low | High | Multiple provider support (Polycam, etc.) |

---

## Conclusion

### Final Recommendation

**DO NOT implement full GaussGym + Veo pipeline now.**

**Instead:**

1. âœ… **Immediate** (this week): Enhance procedural scenes
2. âœ… **Month 1**: Integrate Luma AI (iPhone â†’ 3D)
3. âœ… **Month 3**: Add Blender procedural pipeline
4. â¸ï¸ **Month 6+**: Re-evaluate GaussGym if needed

**Reasoning:**
- Luma AI provides 80% of GaussGym benefits with 20% complexity
- Users need iteration speed, not photorealism for development
- GaussGym is research-grade (may have stability issues)
- Better ROI with proven commercial APIs (Luma)

### When to Revisit GaussGym

**Revisit if:**
- âœ… Luma AI proves limiting (unlikely)
- âœ… Vision-based policies need 3DGS quality (measure this)
- âœ… GaussGym releases stable v1.0
- âœ… User demand for photorealistic training (survey)

**Don't revisit if:**
- âŒ Current solutions meet user needs
- âŒ Cost/benefit doesn't justify dev time
- âŒ Competitors aren't offering it

---

## References

1. **GaussGym Paper**: "GaussGym: Photorealistic RL Environments from Unposed Videos" (Oct 2024)
2. **NKSR**: "Neural Kernel Surface Reconstruction" (NVIDIA, CVPR 2023)
3. **3D Gaussian Splatting**: "3D Gaussian Splatting for Real-Time Radiance Field Rendering" (SIGGRAPH 2023)
4. **Veo 3.1**: Google DeepMind Blog (Jan 2025)
5. **Luma AI**: https://lumalabs.ai/api

---

**Document Version**: 1.0
**Last Updated**: 2025-01-14
**Next Review**: 2025-04-01 (after Phase 2 complete)
**Owner**: Celestial Studio Team
